{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0gVjkSzVEXC",
        "outputId": "57673eb4-9414-4bb2-c178-403dbed607e4"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOgoRbB5-_Rh",
        "outputId": "4a13fa20-af2a-4da1-91d2-a61fdfa323e6"
      },
      "source": [
        "import pandas as pd \r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import string\r\n",
        "import nltk\r\n",
        "import operator\r\n",
        "\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\r\n",
        "from operator import itemgetter\r\n",
        "\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "stopwords = set(stopwords.words(\"english\"))"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaZXIG98VdHD"
      },
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/ML/Intern/result.csv\",encoding='latin-1')"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynZLzZuAzc6V",
        "outputId": "9f7fd80d-2069-4ffa-9965-895006a877ac"
      },
      "source": [
        "train.shape"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(881, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufV_0mycVv2-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "870d1683-d1dc-4ff9-dbb8-fc6b32fd04e6"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>created_at</th>\n",
              "      <th>author/followers_count</th>\n",
              "      <th>author/screen_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>RT @BarackObama: \"We've got to make sure that ...</td>\n",
              "      <td>1395348387</td>\n",
              "      <td>165</td>\n",
              "      <td>tracyscanlan3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not a cult, at all-&amp;gt; RT @BarackObama: \"We n...</td>\n",
              "      <td>1395348386</td>\n",
              "      <td>1162</td>\n",
              "      <td>bakedflounder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RT @YDMO: RT if you agree with @BarackObama: M...</td>\n",
              "      <td>1395348381</td>\n",
              "      <td>1026</td>\n",
              "      <td>mizzoudems</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @BarackObama: President Obama: Today, more ...</td>\n",
              "      <td>1395348380</td>\n",
              "      <td>174</td>\n",
              "      <td>chantelltelle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @BarackObama: \"We've got to make sure that ...</td>\n",
              "      <td>1395348378</td>\n",
              "      <td>234</td>\n",
              "      <td>Germontani</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...  author/screen_name\n",
              "0  RT @BarackObama: \"We've got to make sure that ...  ...       tracyscanlan3\n",
              "1  Not a cult, at all-&gt; RT @BarackObama: \"We n...  ...       bakedflounder\n",
              "2  RT @YDMO: RT if you agree with @BarackObama: M...  ...          mizzoudems\n",
              "3  RT @BarackObama: President Obama: Today, more ...  ...       chantelltelle\n",
              "4  RT @BarackObama: \"We've got to make sure that ...  ...          Germontani\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBQlhpbgV4ye",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "1617b035-134b-4454-83be-e3640318c5f6"
      },
      "source": [
        "train.tail()"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>created_at</th>\n",
              "      <th>author/followers_count</th>\n",
              "      <th>author/screen_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>876</th>\n",
              "      <td>RT @steveyknight: It worked! https://t.co/S8Zq...</td>\n",
              "      <td>1394714187</td>\n",
              "      <td>94</td>\n",
              "      <td>AshButta</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>877</th>\n",
              "      <td>It worked! https://t.co/S8Zq4LKTNe MT @David_C...</td>\n",
              "      <td>1394714116</td>\n",
              "      <td>1381</td>\n",
              "      <td>steveyknight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>878</th>\n",
              "      <td>RT @jackpalmer88: MT @David_Cameron: Falafel w...</td>\n",
              "      <td>1394708445</td>\n",
              "      <td>674</td>\n",
              "      <td>Falafel_Junkie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>MT @David_Cameron: Falafel with the Mayor of B...</td>\n",
              "      <td>1394707348</td>\n",
              "      <td>1197</td>\n",
              "      <td>jackpalmer88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>880</th>\n",
              "      <td>Also comes with a healthy dose of fucking the ...</td>\n",
              "      <td>1394702757</td>\n",
              "      <td>203</td>\n",
              "      <td>timfromdagworth</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  text  ...  author/screen_name\n",
              "876  RT @steveyknight: It worked! https://t.co/S8Zq...  ...            AshButta\n",
              "877  It worked! https://t.co/S8Zq4LKTNe MT @David_C...  ...        steveyknight\n",
              "878  RT @jackpalmer88: MT @David_Cameron: Falafel w...  ...      Falafel_Junkie\n",
              "879  MT @David_Cameron: Falafel with the Mayor of B...  ...        jackpalmer88\n",
              "880  Also comes with a healthy dose of fucking the ...  ...     timfromdagworth\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8kwwqbk0BQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605622c0-677d-46a8-bec0-3ffd52de6dc3"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 881 entries, 0 to 880\n",
            "Data columns (total 4 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   text                    881 non-null    object\n",
            " 1   created_at              881 non-null    int64 \n",
            " 2   author/followers_count  881 non-null    int64 \n",
            " 3   author/screen_name      881 non-null    object\n",
            "dtypes: int64(2), object(2)\n",
            "memory usage: 27.7+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0iFXEPLV9As",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c2ac2d7-5770-4bb2-d35e-d3636f5907e9"
      },
      "source": [
        "train.isnull().sum()"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text                      0\n",
              "created_at                0\n",
              "author/followers_count    0\n",
              "author/screen_name        0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA0XdITGWDMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dc16424-3592-47f7-e290-bf9fe1f52e36"
      },
      "source": [
        "train.isnull().values.any()"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WixHd_fWPut",
        "outputId": "0c21f6c0-3354-4fe9-bd9b-fe3fe7628462"
      },
      "source": [
        "!pip install tweet-preprocessor"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweet-preprocessor in /usr/local/lib/python3.6/dist-packages (0.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozUa_a_y6rOc"
      },
      "source": [
        "def remove_pattern(text, pattern_regex):\r\n",
        "    r = re.findall(pattern_regex, text)\r\n",
        "    for i in r:\r\n",
        "        text = re.sub(i, '', text)\r\n",
        "    return text \r\n",
        "train['text2'] = np.vectorize(remove_pattern)(train['text'], \"@[\\w]*: | *RT*\")"
      ],
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIqlRhoo32Go"
      },
      "source": [
        "def remove_URL(text):\r\n",
        "  text = re.sub(r\"http\\S+\", \"\", text)\r\n",
        "  return text\r\n",
        "train['text2'] = train['text2'].apply(lambda x: remove_URL(x))"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yUQ0oKcCj-4"
      },
      "source": [
        "def remove_punct(text):\r\n",
        "    text  = \"\".join([char for char in text if char not in string.punctuation])\r\n",
        "    text = re.sub('[0-9]+', '', text)\r\n",
        "    return text\r\n",
        "train['text2'] = train['text2'].apply(lambda x: remove_punct(x))"
      ],
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxQTI3SbC_zS"
      },
      "source": [
        "def tokenization(text):\r\n",
        "    text = re.split('\\W+', text)\r\n",
        "    return text\r\n",
        "train['text2'] = train['text2'].apply(lambda x: tokenization(x.lower()))"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAUxyK7FDWY1"
      },
      "source": [
        "stopword = nltk.corpus.stopwords.words('english')\r\n",
        "def remove_stopwords(text):\r\n",
        "    text = [word for word in text if word not in stopword]\r\n",
        "    return text\r\n",
        "train['text2'] = train['text2'].apply(lambda x: remove_stopwords(x))"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8rwiFPVEPhP"
      },
      "source": [
        "wn = nltk.WordNetLemmatizer()\r\n",
        "def lemmatizer(text):\r\n",
        "    text = [wn.lemmatize(word) for word in text]\r\n",
        "    return text\r\n",
        "train['text2'] = train['text2'].apply(lambda x: lemmatizer(x))"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoVrU6thfO_9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "e35854c4-3e39-4bdd-aa6c-a228b1bd00ef"
      },
      "source": [
        "train = train[['text2','author/followers_count','text','created_at','author/screen_name']]\r\n",
        "train.head()"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text2</th>\n",
              "      <th>author/followers_count</th>\n",
              "      <th>text</th>\n",
              "      <th>created_at</th>\n",
              "      <th>author/screen_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[, weve, got, make, sure, every, woman, opport...</td>\n",
              "      <td>165</td>\n",
              "      <td>RT @BarackObama: \"We've got to make sure that ...</td>\n",
              "      <td>1395348387</td>\n",
              "      <td>tracyscanlan3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[cult, allgt, nag, love, â, michelleobama, mom...</td>\n",
              "      <td>1162</td>\n",
              "      <td>Not a cult, at all-&amp;gt; RT @BarackObama: \"We n...</td>\n",
              "      <td>1395348386</td>\n",
              "      <td>bakedflounder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[, agree, mo, legislature, isnt, right, thing,...</td>\n",
              "      <td>1026</td>\n",
              "      <td>RT @YDMO: RT if you agree with @BarackObama: M...</td>\n",
              "      <td>1395348381</td>\n",
              "      <td>mizzoudems</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[, president, obama, today, woman, bread, winn...</td>\n",
              "      <td>174</td>\n",
              "      <td>RT @BarackObama: President Obama: Today, more ...</td>\n",
              "      <td>1395348380</td>\n",
              "      <td>chantelltelle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[, weve, got, make, sure, every, woman, opport...</td>\n",
              "      <td>234</td>\n",
              "      <td>RT @BarackObama: \"We've got to make sure that ...</td>\n",
              "      <td>1395348378</td>\n",
              "      <td>Germontani</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               text2  ...  author/screen_name\n",
              "0  [, weve, got, make, sure, every, woman, opport...  ...       tracyscanlan3\n",
              "1  [cult, allgt, nag, love, â, michelleobama, mom...  ...       bakedflounder\n",
              "2  [, agree, mo, legislature, isnt, right, thing,...  ...          mizzoudems\n",
              "3  [, president, obama, today, woman, bread, winn...  ...       chantelltelle\n",
              "4  [, weve, got, make, sure, every, woman, opport...  ...          Germontani\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLluiohOjc5p"
      },
      "source": [
        "corpus = []\r\n",
        "length = len(train['text2'])\r\n",
        "for i in range(0,length):\r\n",
        "  w = train['text2'][i]\r\n",
        "  w=' '.join(w)\r\n",
        "  corpus.append(w)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_YSwMJKm_AJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0a3b4e6-55b6-4cce-c299-a2ccad9fc975"
      },
      "source": [
        "cv = TfidfVectorizer()\r\n",
        "X = cv.fit_transform(corpus).toarray()\r\n",
        "print(X.shape)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(881, 1890)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AncAoxesAaI-"
      },
      "source": [
        "threshold = 0.03\r\n",
        "import scipy\r\n",
        "from scipy.cluster import  hierarchy\r\n",
        "Z = hierarchy.linkage(X, \"average\", metric=\"cosine\")\r\n",
        "C = hierarchy.fcluster(Z, threshold, criterion=\"distance\")"
      ],
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSzN06tFTwMm"
      },
      "source": [
        "clusters = C.tolist()\r\n",
        "i=0\r\n",
        "for x in clusters:\r\n",
        "  train[\"created_at\"][i] = x\r\n",
        "  i=i+1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO1nENXytRBJ"
      },
      "source": [
        "dict = {}\r\n",
        "for i in range(len(train)):\r\n",
        "  x = train['created_at'][i]\r\n",
        "  if x not in dict:\r\n",
        "    dict[x] = {}\r\n",
        "    dict[x]['tweet'] = []\r\n",
        "  dict[x]['tweet'].append(train['text'][i])\r\n",
        "\r\n",
        "for i in dict:\r\n",
        "  dict[i]['popularity'] = len(dict[i]['tweet'])\r\n"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQiyWg93vLUD"
      },
      "source": [
        "resultList = []\r\n",
        "for cluster in dict.values():\r\n",
        "  resultList.append(cluster)\r\n",
        "resultList = sorted(resultList, key=itemgetter('popularity'), reverse=True)"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wmlUNaQ0Fc-"
      },
      "source": [
        "list1 = []\r\n",
        "list2 = []\r\n",
        "for i in resultList:\r\n",
        "  list1.append(i['tweet'][0])\r\n",
        "  list2.append(i['popularity'])"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n8JbJy1V2yYd"
      },
      "source": [
        "df1 = pd.DataFrame(np.array(list1).reshape(len(list1),1), columns = list(\"A\"))"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQu3uLlm3XXY"
      },
      "source": [
        "df2 = pd.DataFrame(np.array(list2).reshape(len(list2),1), columns=list(\"B\"))"
      ],
      "execution_count": 208,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkO7KL7N4YH3",
        "outputId": "c93278d8-b492-4c90-888c-6700deacbdfb"
      },
      "source": [
        "submission = pd.DataFrame({\r\n",
        "        \"Tweet\": df1['A'],\r\n",
        "        \"Popularity\": df2['B']\r\n",
        "    })\r\n",
        "submission.to_csv('solution.csv')\r\n",
        "print(\"Total number of different tweets are %d\" %len(dict))"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of different tweets are 403\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}